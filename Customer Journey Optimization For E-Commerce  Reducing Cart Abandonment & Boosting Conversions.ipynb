{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8c566-0106-473d-93a2-221db89faa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527cce81-db6a-4176-960c-2152658cc698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tables into DataFrames\n",
    "ecom_events = pd.read_csv(\"ecom_events.csv\")\n",
    "ecom_checkouts = pd.read_csv(\"ecom_checkouts.csv\")\n",
    "ecom_users = pd.read_csv(\"ecom_users.csv\")\n",
    "ecom_products = pd.read_csv(\"ecom_products.csv\")\n",
    "ecom_retention = pd.read_csv(\"ecom_retention.csv\")\n",
    "ecom_ab_tests = pd.read_csv(\"ecom_ab_tests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef901cd8-9e3f-422d-8097-466f6b735ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n1. Users Overview\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFirst few rows of the user dataset:\")\n",
    "print(ecom_users.head())\n",
    "\n",
    "print(\"\\nUsers Info:\")\n",
    "print(ecom_users.info())\n",
    "\n",
    "print(\"\\nUsers Statistics:\")\n",
    "print(ecom_users.describe())\n",
    "\n",
    "print(\"\\n1. Products Overview\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFirst few rows of the product dataset:\")\n",
    "print(ecom_products.head())\n",
    "\n",
    "print(\"\\nProducts Info:\")\n",
    "print(ecom_products.info())\n",
    "\n",
    "print(\"\\nProducts Statistics:\")\n",
    "print(ecom_products.describe())\n",
    "\n",
    "print(\"\\n1. Events Overview\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFirst few rows of the Events dataset:\")\n",
    "print(ecom_events.head())\n",
    "\n",
    "print(\"\\nEvents Info:\")\n",
    "print(ecom_events.info())\n",
    "\n",
    "print(\"\\nEvents Statistics:\")\n",
    "print(ecom_events.describe())\n",
    "\n",
    "print(\"\\n1. Checkouts Overview\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFirst few rows of the Checkouts dataset:\")\n",
    "print(ecom_checkouts.head())\n",
    "\n",
    "print(\"\\nCheckouts Info:\")\n",
    "print(ecom_checkouts.info())\n",
    "\n",
    "print(\"\\nCheckouts Statistics:\")\n",
    "print(ecom_checkouts.describe())\n",
    "\n",
    "print(\"\\n1. Retention Overview\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFirst few rows of the Retention dataset:\")\n",
    "print(ecom_retentions.head())\n",
    "\n",
    "print(\"\\nRetentions Info:\")\n",
    "print(ecom_retentions.info())\n",
    "\n",
    "print(\"\\nRetentions Statistics:\")\n",
    "print(ecom_retentions.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39b0ee-e2d3-4108-a8c4-a3ed9c1eb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null and duplicate values\n",
    "\n",
    "def check_data_issues(df, df_name):\n",
    "    print(f\"Checking data issues for {df_name}...\\n\")\n",
    "    \n",
    "    # Check for null values\n",
    "    null_counts = df.isnull().sum()\n",
    "    print(f\"Null values in {df_name}:\\n{null_counts[null_counts > 0]}\\n\")\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"Number of duplicate rows in {df_name}: {duplicate_count}\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"Total rows: {df.shape[0]}, Total columns: {df.shape[1]}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "check_data_issues(ecom_users, \"ecom_users\")\n",
    "check_data_issues(ecom_products, \"ecom_products\")\n",
    "check_data_issues(ecom_events, \"ecom_events\")\n",
    "check_data_issues(ecom_checkouts, \"ecom_checkouts\")\n",
    "check_data_issues(ecom_retention, \"ecom_retention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efccab8-9366-4495-afba-0cdaeea9e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize categorical values\n",
    "ecom_users['device_preference'] = ecom_users['device_preference'].str.lower().str.strip()\n",
    "ecom_users['preferred_payment'] = ecom_users['preferred_payment'].str.lower().str.strip()\n",
    "ecom_events['device_type'] = ecom_events['device_type'].str.lower().str.strip()\n",
    "ecom_checkouts['payment_method'] = ecom_checkouts['payment_method'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5819f-39e8-475d-bbef-5ac6a159ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Datetime column to proper format\n",
    "# Mapping of DataFrame names to their date columns\n",
    "date_columns_map = {\n",
    "    'ecom_users': ['join_date'],\n",
    "    'ecom_checkouts': ['purchase_time'],\n",
    "    'ecom_events': ['event_time'],\n",
    "    'ecom_retensions': ['last_purchase_date']\n",
    "}\n",
    "\n",
    "# Convert date columns using the mapping\n",
    "for df_name, date_cols in date_columns_map.items():\n",
    "    df = globals().get(df_name)\n",
    "    if df is not None:\n",
    "        for col in date_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_datetime(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1c3d1-1403-43eb-bdf7-4950f9a550b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features\n",
    "ecom_events['hour_of_day'] = ecom_events['event_time'].dt.hour\n",
    "ecom_events['day_of_week'] = ecom_events['event_time'].dt.dayofweek\n",
    "\n",
    "# Compute session duration\n",
    "ecom_events['session_duration_sec'] = ecom_events.groupby('session_id')['time_spent'].transform('sum')\n",
    "\n",
    "# Price Sensitivity Categorization\n",
    "def categorize_price_sensitivity(spend):\n",
    "    if spend >= 500: return 'L'\n",
    "    elif spend >= 100: return 'M'\n",
    "    else: return 'H'\n",
    "ecom_users['price_sensitivity'] = ecom_users['user_id'].map(\n",
    "    ecom_retention.set_index('user_id')['total_spend'].apply(categorize_price_sensitivity))\n",
    "\n",
    "# Cart Abandonment Count\n",
    "ecom_retention['abandoned_carts'] = ecom_events.groupby('user_id')['abandonment_stage'].count()\n",
    "\n",
    "# Calculate completed checkouts and checkout reached per user\n",
    "checkouts_per_user = ecom_checkouts.groupby('user_id')['checkout_id'].count()\n",
    "checkout_reached_per_user = ecom_events.groupby('user_id')['checkout_reached'].sum()\n",
    "checkout_completion_rate = checkouts_per_user / checkout_reached_per_user.replace(0, np.nan)\n",
    "\n",
    "# Assign safely to ecom_retention\n",
    "ecom_retention['checkout_completion_rate'] = ecom_retention['user_id'].map(checkout_completion_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e95e3-48d1-4c7b-9d2e-0f5f7259f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the funnel metrics\n",
    "funnel_steps = ecom_events.groupby('session_id').agg({\n",
    "    'event_type': [\n",
    "        ('viewed_product', lambda x: (x == 'view').any()),\n",
    "        ('added_to_cart', lambda x: (x == 'cart').any()),\n",
    "        ('checkout_started', lambda x: (x == 'checkout_start').any()),\n",
    "        ('shipping_selected', lambda x: (x == 'shipping_selected').any()),\n",
    "        ('purchased', lambda x: ((x == 'purchase') & (ecom_events.loc[x.index, 'purchase_status'] == 'success')).any())\n",
    "    ]\n",
    "}).droplevel(0, axis=1)  # Flatten multi-level columns\n",
    "\n",
    "# Calculate funnel metrics\n",
    "funnel_metrics = pd.DataFrame({\n",
    "    'total_sessions': [len(funnel_steps)],\n",
    "    'product_views': [funnel_steps['viewed_product'].sum()],\n",
    "    'cart_adds': [funnel_steps['added_to_cart'].sum()],\n",
    "    'checkouts_started': [funnel_steps['checkout_started'].sum()],\n",
    "    'shipping_selections': [funnel_steps['shipping_selected'].sum()],\n",
    "    'purchases': [funnel_steps['purchased'].sum()],\n",
    "    \n",
    "    'view_to_cart_rate': [round(100.0 * funnel_steps['added_to_cart'].sum() / funnel_steps['viewed_product'].sum(), 2)],\n",
    "    'cart_to_checkout_rate': [round(100.0 * funnel_steps['checkout_started'].sum() / funnel_steps['added_to_cart'].sum(), 2)],\n",
    "    'checkout_to_shipping_rate': [round(100.0 * funnel_steps['shipping_selected'].sum() / funnel_steps['checkout_started'].sum(), 2)],\n",
    "    'shipping_to_purchase_rate': [round(100.0 * funnel_steps['purchased'].sum() / funnel_steps['shipping_selected'].sum(), 2)],\n",
    "    'overall_conversion_rate': [round(100.0 * funnel_steps['purchased'].sum() / funnel_steps['viewed_product'].sum(), 2)]\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "funnel_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1b699-188f-4578-bbbe-52559654c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the funnel\n",
    "plt.figure(figsize=(10, 6))\n",
    "stages = ['Product Views', 'Cart Adds', 'Checkout Started', 'Shipping Selected', 'Purchases']\n",
    "values = funnel_metrics.iloc[0, 1:6].values\n",
    "\n",
    "sns.barplot(x=values, y=stages, palette='viridis')\n",
    "plt.title('E-Commerce Conversion Funnel', fontsize=16)\n",
    "plt.xlabel('Number of Sessions', fontsize=12)\n",
    "\n",
    "# Add conversion rates\n",
    "for i, (stage, value) in enumerate(zip(stages, values)):\n",
    "    if i > 0:\n",
    "        conv_rate = (value / values[i-1]) * 100\n",
    "        plt.text(value + max(values)*0.05, i, f'{conv_rate:.1f}%', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882f1c3-0834-4fb3-9ba3-91f7b01720d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Funnel data\n",
    "stages = ['Product Views', 'Cart Adds', 'Checkout Started', 'Shipping Selected', 'Purchases']\n",
    "values = funnel_metrics.iloc[0, 1:6].values\n",
    "\n",
    "# Calculate conversion rates\n",
    "conversion_from_previous = [None] + [round((curr / prev) * 100, 1) for prev, curr in zip(values[:-1], values[1:])]\n",
    "conversion_from_start = [round((val / values[0]) * 100, 1) for val in values]\n",
    "\n",
    "# Build annotations for clarity\n",
    "annotations = []\n",
    "for i, (stage, val, conv_prev, conv_init) in enumerate(zip(stages, values, conversion_from_previous, conversion_from_start)):\n",
    "    text = f\"{val:,} sessions\"\n",
    "    if conv_prev is not None:\n",
    "        text += f\"<br>{conv_prev}% from previous\"\n",
    "    text += f\"<br>{conv_init}% from start\"\n",
    "    annotations.append(dict(\n",
    "        x=val,\n",
    "        y=stage,\n",
    "        text=text,\n",
    "        showarrow=False,\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"middle\",\n",
    "        font=dict(size=12),\n",
    "        bgcolor=\"rgba(255,255,255,0.6)\",\n",
    "        bordercolor=\"gray\",\n",
    "        borderwidth=1\n",
    "    ))\n",
    "\n",
    "# Plot the funnel\n",
    "fig = go.Figure(go.Funnel(\n",
    "    y=stages,\n",
    "    x=values,\n",
    "    textinfo=\"value+percent previous\",\n",
    "    opacity=0.9,\n",
    "    marker=dict(color='mediumseagreen', line=dict(width=2, color='gray'))\n",
    "))\n",
    "\n",
    "# Update layout with annotations\n",
    "fig.update_layout(\n",
    "    title=\"ðŸ›’ E-Commerce Conversion Funnel\",\n",
    "    annotations=annotations,\n",
    "    margin=dict(l=80, r=80, t=80, b=40),\n",
    "    font=dict(family=\"Arial\", size=14),\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab66fa7a-9830-4951-887e-e408fc862d2b",
   "metadata": {},
   "source": [
    "## Cart Abandonment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20548ef2-6270-483a-864b-08229fb8b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart_abandonment_analysis():\n",
    "    # Calculate cart abandonment rate\n",
    "    cart_sessions = ecom_events[ecom_events['event_type'] == 'cart']['session_id'].nunique()\n",
    "    purchase_sessions = ecom_events[(ecom_events['event_type'] == 'purchase') & \n",
    "                             (ecom_events['purchase_status'] == 'success')]['session_id'].nunique()\n",
    "    abandonment_rate = round((cart_sessions - purchase_sessions) / cart_sessions * 100, 1)\n",
    "    \n",
    "    # Reasons for abandonment\n",
    "    abandonment_reasons = ecom_events[ecom_events['event_type'].isin(['cart_abandoned', 'checkout_abandoned'])]\n",
    "    reasons_count = abandonment_reasons['abandonment_stage'].value_counts().reset_index()\n",
    "    reasons_count.columns = ['abandonment_stage', 'count']\n",
    "    \n",
    "    # Average time spent before abandonment\n",
    "    abandoned_sessions = abandonment_reasons['session_id'].unique()\n",
    "    abandoned_time = ecom_events[(ecom_events['session_id'].isin(abandoned_sessions)) & \n",
    "                          (ecom_events['event_type'] == 'session_end')]\n",
    "    avg_time_before_abandonment = round(abandoned_time['session_duration_sec'].mean() / 60, 1)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.pie(reasons_count['count'], labels=reasons_count['abandonment_stage'], autopct='%1.1f%%')\n",
    "    plt.title('Abandonment Reasons Distribution')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x=['Cart Abandonment Rate'], y=[abandonment_rate])\n",
    "    plt.title('Overall Cart Abandonment Rate')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAverage time before abandonment: {avg_time_before_abandonment} minutes\")\n",
    "    return abandonment_rate, reasons_count\n",
    "\n",
    "abandonment_rate, reasons_count = cart_abandonment_analysis()\n",
    "print(\"\\nCart Abandonment Analysis Results:\")\n",
    "print(f\"Overall abandonment rate: {abandonment_rate}%\")\n",
    "print(\"Abandonment reasons:\")\n",
    "print(reasons_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b7c29-124d-4ef5-a2f3-b67faf0593c7",
   "metadata": {},
   "source": [
    "## Payment Failure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891dde5a-51ea-4808-b940-20cb8f934642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment failure analysis\n",
    "payment_events = ecom_events[\n",
    "    (ecom_events['event_type'] == 'purchase') &\n",
    "    (ecom_events['purchase_status'].isin(['success', 'failed']))\n",
    "]\n",
    "\n",
    "payment_stats = payment_events.groupby(['purchase_status', 'payment_method']).agg(\n",
    "    count=('session_id', 'nunique'),\n",
    "    avg_page_load=('page_load_sec', 'mean'),\n",
    "    avg_time_spent=('time_spent', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nPayment Success/Failure Rates:\")\n",
    "print(payment_stats.pivot(index='payment_method', columns='purchase_status', values='count'))\n",
    "\n",
    "# Time of day impact\n",
    "payment_events['hour'] = payment_events['event_time'].dt.hour\n",
    "time_impact = payment_events.groupby(['hour', 'purchase_status'])['session_id'].nunique().unstack()\n",
    "time_impact['failure_rate'] = time_impact['failed'] / (time_impact['success'] + time_impact['failed'])\n",
    "print(\"\\nFailure Rate by Hour:\")\n",
    "print(time_impact[['failure_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ada7a1-681c-47ad-a820-db36389330be",
   "metadata": {},
   "source": [
    "## Device Segment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd4c0f-a747-4066-b961-354bda454a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_segment_analysis():\n",
    "    # Merge device info from users to events\n",
    "    device_events = ecom_events.merge(ecom_users[['user_id', 'device_preference']], on='user_id')\n",
    "    \n",
    "    # Calculate conversion rates by device\n",
    "    device_funnel = device_events.groupby('device_preference').agg({\n",
    "        'session_id': 'nunique',\n",
    "        'event_type': lambda x: (x == 'purchase').sum()\n",
    "    }).rename(columns={'session_id': 'total_sessions', 'event_type': 'purchases'})\n",
    "    \n",
    "    device_funnel['conversion_rate'] = round(device_funnel['purchases'] / device_funnel['total_sessions'] * 100, 1)\n",
    "    \n",
    "    # Calculate average session duration by device\n",
    "    session_duration = device_events[device_events['event_type'] == 'session_end']\n",
    "    avg_duration = session_duration.groupby('device_preference')['session_duration_sec'].mean().reset_index()\n",
    "    avg_duration['session_duration_min'] = round(avg_duration['session_duration_sec'] / 60, 1)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x='device_preference', y='conversion_rate', data=device_funnel.reset_index())\n",
    "    plt.title('Conversion Rate by Device Type')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x='device_preference', y='session_duration_min', data=avg_duration)\n",
    "    plt.title('Average Session Duration by Device')\n",
    "    plt.ylabel('Minutes')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return device_funnel, avg_duration\n",
    "\n",
    "device_results, duration_results = device_segment_analysis()\n",
    "print(\"\\nDevice Segment Analysis Results:\")\n",
    "print(device_results)\n",
    "print(\"\\nAverage Session Duration by Device:\")\n",
    "print(duration_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64166f1-87b0-4c8e-876d-a11ed7ee7894",
   "metadata": {},
   "source": [
    "## Payment Method Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b30f9-f709-4dff-977d-5fa613c77181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def payment_method_analysis():\n",
    "    # Payment method distribution\n",
    "    payment_dist = ecom_checkouts['payment_method'].value_counts(normalize=True).reset_index()\n",
    "    payment_dist.columns = ['payment_method', 'percentage']\n",
    "    payment_dist['percentage'] = round(payment_dist['percentage'] * 100, 1)\n",
    "    \n",
    "    # Payment method vs conversion\n",
    "    payment_success = ecom_events[ecom_events['event_type'] == 'purchase']\n",
    "    payment_success = payment_success.merge(ecom_users[['user_id', 'preferred_payment']], on='user_id')\n",
    "    payment_success_rate = payment_success.groupby('preferred_payment')['purchase_status'].apply(\n",
    "        lambda x: (x == 'success').mean() * 100).reset_index()\n",
    "    payment_success_rate.columns = ['payment_method', 'success_rate']\n",
    "    \n",
    "    # Average order value by payment method\n",
    "    aov_by_payment = ecom_checkouts.groupby('payment_method')['total_paid'].mean().reset_index()\n",
    "    aov_by_payment['total_paid'] = round(aov_by_payment['total_paid'], 2)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.barplot(x='payment_method', y='percentage', data=payment_dist)\n",
    "    plt.title('Payment Method Distribution')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.barplot(x='payment_method', y='success_rate', data=payment_success_rate)\n",
    "    plt.title('Payment Success Rate by Method')\n",
    "    plt.ylabel('Success Rate (%)')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.barplot(x='payment_method', y='total_paid', data=aov_by_payment)\n",
    "    plt.title('Average Order Value by Payment Method')\n",
    "    plt.ylabel('Amount ($)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return payment_dist, payment_success_rate, aov_by_payment\n",
    "\n",
    "payment_dist, success_rates, aov_payment = payment_method_analysis()\n",
    "print(\"\\nPayment Method Analysis Results:\")\n",
    "print(\"Payment method distribution:\")\n",
    "print(payment_dist)\n",
    "print(\"\\nPayment success rates:\")\n",
    "print(success_rates)\n",
    "print(\"\\nAverage order value by payment method:\")\n",
    "print(aov_payment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef94837-2e84-4d19-9ed5-321a3a098858",
   "metadata": {},
   "source": [
    "## Retention Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa26e3-e085-4be8-aa9d-92b9280d74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retention_analysis():\n",
    "    # Cohort analysis\n",
    "    ecom_users['join_month'] = ecom_users['join_date'].dt.to_period('M')\n",
    "    ecom_checkouts['purchase_month'] = ecom_checkouts['purchase_time'].dt.to_period('M')\n",
    "    \n",
    "    cohort_data = ecom_checkouts.merge(ecom_users[['user_id', 'join_month']], on='user_id')\n",
    "    cohort_data['cohort_index'] = (cohort_data['purchase_month'] - cohort_data['join_month']).apply(lambda x: x.n)\n",
    "    \n",
    "    cohort_pivot = cohort_data.pivot_table(index='join_month', \n",
    "                                         columns='cohort_index', \n",
    "                                         values='user_id', \n",
    "                                         aggfunc=pd.Series.nunique)\n",
    "    \n",
    "    cohort_size = cohort_pivot.iloc[:, 0]\n",
    "    retention_matrix = cohort_pivot.divide(cohort_size, axis=0)\n",
    "    \n",
    "    # Calculate overall retention metrics\n",
    "    repeat_customers = ecom_retention[ecom_retention['total_purchases'] > 1].shape[0]\n",
    "    repeat_rate = round(repeat_customers / len(ecom_retention) * 100, 1)\n",
    "    avg_purchases = round(ecom_retention['total_purchases'].mean(), 1)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(retention_matrix, annot=True, fmt='.0%', cmap='Blues')\n",
    "    plt.title('Monthly Cohort Retention Rates')\n",
    "    plt.ylabel('Cohort Month')\n",
    "    plt.xlabel('Months Since First Purchase')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(ecom_retention['days_since_last_purchase'], bins=30, kde=True)\n",
    "    plt.title('Days Since Last Purchase Distribution')\n",
    "    plt.xlabel('Days')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nRepeat customer rate: {repeat_rate}%\")\n",
    "    print(f\"Average purchases per customer: {avg_purchases}\")\n",
    "    return retention_matrix\n",
    "\n",
    "retention_matrix = retention_analysis()\n",
    "print(\"\\nRetention Matrix:\")\n",
    "print(retention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b5e51-8b02-40a6-9e8c-9de31153f826",
   "metadata": {},
   "source": [
    "## Checkout Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b1922a-ff61-4492-b580-f31b4745d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkout_optimization_analysis():\n",
    "    # Get checkout timing data\n",
    "    checkout_timing = ecom_events[ecom_events['event_type'].isin(['checkout_start', 'shipping_selected', \n",
    "                                                     'payment_entered', 'purchase'])]\n",
    "    \n",
    "    # Calculate step completion rates\n",
    "    step_completion = checkout_timing.groupby('checkout_step')['session_id'].nunique().reset_index()\n",
    "    step_completion['completion_rate'] = round(step_completion['session_id'] / step_completion['session_id'].max() * 100, 1)\n",
    "    \n",
    "    # Calculate average time per step\n",
    "    step_times = checkout_timing.groupby('checkout_step')['step_time_sec'].mean().reset_index()\n",
    "    step_times['step_time_sec'] = round(step_times['step_time_sec'], 1)\n",
    "    \n",
    "    # Impact of page load time on conversion\n",
    "    checkout_sessions = ecom_events[ecom_events['event_type'] == 'checkout_start']['session_id'].unique()\n",
    "    checkout_events = ecom_events[ecom_events['session_id'].isin(checkout_sessions)]\n",
    "    \n",
    "    page_load_impact = checkout_events.groupby('session_id').agg({\n",
    "        'page_load_sec': 'mean',\n",
    "        'event_type': lambda x: 'purchase' in x.values\n",
    "    }).reset_index()\n",
    "    page_load_impact.columns = ['session_id', 'avg_page_load', 'converted']\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.barplot(x='checkout_step', y='completion_rate', data=step_completion)\n",
    "    plt.title('Checkout Step Completion Rates')\n",
    "    plt.ylabel('Completion Rate (%)')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.barplot(x='checkout_step', y='step_time_sec', data=step_times)\n",
    "    plt.title('Average Time per Checkout Step')\n",
    "    plt.ylabel('Seconds')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.boxplot(x='converted', y='avg_page_load', data=page_load_impact)\n",
    "    plt.title('Page Load Time vs Conversion')\n",
    "    plt.xlabel('Converted')\n",
    "    plt.ylabel('Average Page Load (sec)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return step_completion, step_times, page_load_impact\n",
    "\n",
    "step_completion, step_times, page_load_impact = checkout_optimization_analysis()\n",
    "print(\"\\nCheckout Optimization Analysis Results:\")\n",
    "print(\"Step completion rates:\")\n",
    "print(step_completion)\n",
    "print(\"\\nAverage time per step:\")\n",
    "print(step_times)\n",
    "print(\"\\nPage load impact on conversion:\")\n",
    "print(page_load_impact.groupby('converted')['avg_page_load'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139f7d8-f6e1-4835-a891-361a2364fabf",
   "metadata": {},
   "source": [
    "## RFM (Recency, Frequency, Monetary) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b01c80-76fa-430d-b0dd-948492cc31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def rfm_analysis():\n",
    "    # Prepare RFM data\n",
    "    rfm_data = ecom_checkouts.groupby('user_id').agg({\n",
    "        'purchase_time': lambda x: (datetime.now() - x.max()).days,\n",
    "        'checkout_id': 'count',\n",
    "        'total_paid': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    rfm_data.columns = ['user_id', 'recency', 'frequency', 'monetary']\n",
    "    \n",
    "    # Create RFM scores with duplicate handling\n",
    "    try:\n",
    "        rfm_data['r_score'] = pd.qcut(rfm_data['recency'], q=4, labels=[4, 3, 2, 1], duplicates='drop')\n",
    "        rfm_data['f_score'] = pd.qcut(rfm_data['frequency'].rank(method='first'), q=4, labels=[1, 2, 3, 4])\n",
    "        rfm_data['m_score'] = pd.qcut(rfm_data['monetary'], q=4, labels=[1, 2, 3, 4], duplicates='drop')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in bucketing: {e}\")\n",
    "        print(\"\\nValue counts that caused problems:\")\n",
    "        print(\"Recency:\", rfm_data['recency'].value_counts().head())\n",
    "        print(\"Frequency:\", rfm_data['frequency'].value_counts().head())\n",
    "        print(\"Monetary:\", rfm_data['monetary'].value_counts().head())\n",
    "        raise\n",
    "    \n",
    "    rfm_data['rfm_score'] = rfm_data['r_score'].astype(str) + rfm_data['f_score'].astype(str) + rfm_data['m_score'].astype(str)\n",
    "    \n",
    "    # Segmentation (unchanged)\n",
    "    segment_map = {\n",
    "        r'[4][4][4]': 'Champions',\n",
    "        r'[3-4][3-4][3-4]': 'Loyal Customers',\n",
    "        r'[3-4][1-3][1-3]': 'Potential Loyalists',\n",
    "        r'[4][1][1]': 'New Customers',\n",
    "        r'[2-3][2-3][2-3]': 'Need Attention',\n",
    "        r'[1-2][3-4][3-4]': 'At Risk',\n",
    "        r'[1-2][1-2][1-2]': 'Hibernating',\n",
    "        r'[1][1-4][1-4]': 'Lost'\n",
    "    }\n",
    "    \n",
    "    rfm_data['segment'] = rfm_data['rfm_score'].replace(segment_map, regex=True)\n",
    "    \n",
    "    # Visualization (unchanged)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    segment_counts = rfm_data['segment'].value_counts().reset_index()\n",
    "    sns.barplot(x='index', y='segment', data=segment_counts)\n",
    "    plt.title('Customer Segments Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics (unchanged)\n",
    "    segment_stats = rfm_data.groupby('segment').agg({\n",
    "        'recency': 'mean',\n",
    "        'frequency': 'mean',\n",
    "        'monetary': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(\"\\nRFM Segment Statistics:\")\n",
    "    print(segment_stats)\n",
    "    \n",
    "    return rfm_data\n",
    "\n",
    "rfm_results = rfm_analysis()\n",
    "print(\"\\nRFM Analysis Results:\")\n",
    "print(rfm_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bace8d-eb0c-461f-b0e8-057aa8cb8228",
   "metadata": {},
   "source": [
    "## Discount Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209830f9-1cbe-49d9-838a-0f82f84cde13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_impact_analysis():\n",
    "    # Get discount data from events\n",
    "    discount_data = ecom_events[ecom_events['event_type'] == 'cart'].merge(\n",
    "        ecom_products[['product_id', 'discount_eligible', 'discount_tier']], on='product_id')\n",
    "    \n",
    "    # Calculate conversion with/without discount\n",
    "    discount_conversion = discount_data.groupby('discount_applied').agg({\n",
    "        'session_id': 'nunique',\n",
    "        'event_type': lambda x: (ecom_events[(ecom_events['session_id'].isin(x)) & \n",
    "                                      (ecom_events['event_type'] == 'purchase') & \n",
    "                                      (ecom_events['purchase_status'] == 'success')]['session_id'].nunique())\n",
    "    }).reset_index()\n",
    "    \n",
    "    discount_conversion.columns = ['discount_applied', 'sessions', 'purchases']\n",
    "    discount_conversion['conversion_rate'] = round(discount_conversion['purchases'] / discount_conversion['sessions'] * 100, 1)\n",
    "    \n",
    "    # Discount tier analysis\n",
    "    discount_tier_data = discount_data[discount_data['discount_applied'] == 'TRUE']\n",
    "    tier_conversion = discount_tier_data.groupby('discount_tier').agg({\n",
    "        'session_id': 'nunique',\n",
    "        'event_type': lambda x: (ecom_events[(ecom_events['session_id'].isin(x)) & \n",
    "                                      (ecom_events['event_type'] == 'purchase') & \n",
    "                                      (ecom_events['purchase_status'] == 'success')]['session_id'].nunique())\n",
    "    }).reset_index()\n",
    "    \n",
    "    tier_conversion.columns = ['discount_tier', 'sessions', 'purchases']\n",
    "    tier_conversion['conversion_rate'] = round(tier_conversion['purchases'] / tier_conversion['sessions'] * 100, 1)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x='discount_applied', y='conversion_rate', data=discount_conversion)\n",
    "    plt.title('Conversion Rate: Discount vs No Discount')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x='discount_tier', y='conversion_rate', data=tier_conversion)\n",
    "    plt.title('Conversion Rate by Discount Tier')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return discount_conversion, tier_conversion\n",
    "\n",
    "discount_results, tier_results = discount_impact_analysis()\n",
    "print(\"\\nDiscount Impact Analysis Results:\")\n",
    "print(\"Discount vs no discount:\")\n",
    "print(discount_results)\n",
    "print(\"\\nBy discount tier:\")\n",
    "print(tier_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007808a-2cfc-4f63-9868-337c298338bb",
   "metadata": {},
   "source": [
    "## Shipping Fee Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a4a45-4b3d-421c-b64f-90285cdd7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shipping_fee_analysis():\n",
    "    # Get shipping fee data\n",
    "    shipping_data = ecom_events[ecom_events['event_type'] == 'shipping_selected']\n",
    "    \n",
    "    # Shipping fee vs conversion\n",
    "    shipping_conversion = shipping_data.groupby('shipping_fee').agg({\n",
    "        'session_id': 'nunique',\n",
    "        'event_type': lambda x: (ecom_events[(ecom_events['session_id'].isin(x)) & \n",
    "                                      (ecom_events['event_type'] == 'purchase') & \n",
    "                                      (ecom_events['purchase_status'] == 'success')]['session_id'].nunique())\n",
    "    }).reset_index()\n",
    "    \n",
    "    shipping_conversion.columns = ['shipping_fee', 'sessions', 'purchases']\n",
    "    shipping_conversion['conversion_rate'] = round(shipping_conversion['purchases'] / shipping_conversion['sessions'] * 100, 1)\n",
    "    \n",
    "    # Free shipping impact\n",
    "    shipping_conversion['free_shipping'] = shipping_conversion['shipping_fee'] == 0\n",
    "    free_shipping_impact = shipping_conversion.groupby('free_shipping')['conversion_rate'].mean().reset_index()\n",
    "    \n",
    "    # A/B test results\n",
    "    ecom_ab_results = ecom_ab_tests.merge(ecom_events[ecom_events['event_type'] == 'purchase'][['session_id', 'purchase_status']], \n",
    "                              on='session_id', how='left')\n",
    "    ecom_ab_results['converted'] = ecom_ab_results['purchase_status'] == 'success'\n",
    "    \n",
    "    variant_conversion = ecom_ab_results.groupby('variant')['converted'].mean().reset_index()\n",
    "    variant_conversion['conversion_rate'] = round(variant_conversion['converted'] * 100, 1)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x='free_shipping', y='conversion_rate', data=free_shipping_impact)\n",
    "    plt.title('Conversion Rate: Free Shipping vs Paid Shipping')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x='variant', y='conversion_rate', data=variant_conversion)\n",
    "    plt.title('A/B Test: Shipping Threshold Variants')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return free_shipping_impact, variant_conversion\n",
    "\n",
    "free_shipping_results, ab_test_results = shipping_fee_analysis()\n",
    "print(\"\\nShipping Fee Impact Analysis Results:\")\n",
    "print(\"Free shipping impact:\")\n",
    "print(free_shipping_results)\n",
    "print(\"\\nA/B test results:\")\n",
    "print(ab_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70172a-5e5a-4864-a410-45c85a90f892",
   "metadata": {},
   "source": [
    "## Time Based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbee0e7-70a9-497b-bfe2-0adc72e4783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_analysis():\n",
    "    # Hourly patterns\n",
    "    ecom_events['hour'] = pd.to_datetime(ecom_events['event_time']).dt.hour\n",
    "    hourly_activity = ecom_events.groupby('hour')['session_id'].nunique().reset_index()\n",
    "    \n",
    "    # Day of week patterns\n",
    "    ecom_events['day_of_week'] = pd.to_datetime(ecom_events['event_time']).dt.day_name()\n",
    "    dow_activity = ecom_events.groupby('day_of_week')['session_id'].nunique().reset_index()\n",
    "    \n",
    "    # Monthly trends\n",
    "    ecom_events['month'] = pd.to_datetime(ecom_events['event_time']).dt.to_period('M')\n",
    "    monthly_trends = ecom_events.groupby('month')['session_id'].nunique().reset_index()\n",
    "    monthly_trends['month'] = monthly_trends['month'].astype(str)\n",
    "    \n",
    "    # Conversion rate by time\n",
    "    purchase_hour = ecom_events[ecom_events['event_type'] == 'purchase']\n",
    "    purchase_hour = purchase_hour[purchase_hour['purchase_status'] == 'success']\n",
    "    purchase_hour['hour'] = pd.to_datetime(purchase_hour['event_time']).dt.hour\n",
    "    hourly_conversion = purchase_hour.groupby('hour')['session_id'].nunique().reset_index()\n",
    "    hourly_conversion = hourly_conversion.merge(hourly_activity, on='hour')\n",
    "    hourly_conversion['conversion_rate'] = round(hourly_conversion['session_id_x'] / hourly_conversion['session_id_y'] * 100, 1)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.lineplot(x='hour', y='session_id', data=hourly_activity)\n",
    "    plt.title('Hourly Activity Pattern')\n",
    "    plt.ylabel('Number of Sessions')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='day_of_week', y='session_id', data=dow_activity, \n",
    "               order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "    plt.title('Activity by Day of Week')\n",
    "    plt.ylabel('Number of Sessions')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.lineplot(x='month', y='session_id', data=monthly_trends)\n",
    "    plt.title('Monthly Activity Trend')\n",
    "    plt.ylabel('Number of Sessions')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.lineplot(x='hour', y='conversion_rate', data=hourly_conversion)\n",
    "    plt.title('Hourly Conversion Rate')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return hourly_activity, dow_activity, monthly_trends, hourly_conversion\n",
    "\n",
    "hourly_results, dow_results, monthly_results, hourly_conversion = time_based_analysis()\n",
    "print(\"\\nTime-Based Analysis Results:\")\n",
    "print(\"Hourly activity:\")\n",
    "print(hourly_results)\n",
    "print(\"\\nDay of week activity:\")\n",
    "print(dow_results)\n",
    "print(\"\\nMonthly trends:\")\n",
    "print(monthly_results)\n",
    "print(\"\\nHourly conversion rates:\")\n",
    "print(hourly_conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d944e-e506-47e0-87f8-648625226eef",
   "metadata": {},
   "source": [
    "## Product Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec8fb7-c9e0-4c93-ae99-5c98366c14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_category_analysis():\n",
    "    # Merge product data with events\n",
    "    category_data = ecom_events.merge(ecom_products[['product_id', 'category_code', 'brand']], on='product_id')\n",
    "    \n",
    "    # Category popularity\n",
    "    category_popularity = category_data.groupby('category_code')['session_id'].nunique().reset_index()\n",
    "    category_popularity.columns = ['category', 'sessions']\n",
    "    category_popularity['percentage'] = round(category_popularity['sessions'] / category_popularity['sessions'].sum() * 100, 1)\n",
    "    \n",
    "    # Category conversion rates\n",
    "    category_conversion = category_data[category_data['event_type'] == 'view'].groupby('category_code')['session_id'].nunique().reset_index()\n",
    "    category_conversion.columns = ['category', 'views']\n",
    "    \n",
    "    purchases = category_data[(category_data['event_type'] == 'purchase') & \n",
    "                            (category_data['purchase_status'] == 'success')]\n",
    "    category_purchases = purchases.groupby('category_code')['session_id'].nunique().reset_index()\n",
    "    category_purchases.columns = ['category', 'purchases']\n",
    "    \n",
    "    category_conversion = category_conversion.merge(category_purchases, on='category', how='left').fillna(0)\n",
    "    category_conversion['conversion_rate'] = round(category_conversion['purchases'] / category_conversion['views'] * 100, 1)\n",
    "    \n",
    "    # Price difference impact\n",
    "    price_diff_data =ecom_products.merge(\n",
    "        category_data[category_data['event_type'] == 'purchase'][['product_id', 'session_id']],\n",
    "        on='product_id'\n",
    "    )\n",
    "    \n",
    "    price_diff_impact = price_diff_data.groupby(pd.cut(price_diff_data['price_diff_pct'], \n",
    "                                                     bins=[-100, -10, 0, 10, 100]))['session_id'].nunique().reset_index()\n",
    "    price_diff_impact.columns = ['price_diff_range', 'purchases']\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x='percentage', y='category', data=category_popularity.sort_values('percentage', ascending=False))\n",
    "    plt.title('Category Popularity')\n",
    "    plt.xlabel('Percentage of Sessions (%)')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='conversion_rate', y='category', \n",
    "               data=category_conversion.sort_values('conversion_rate', ascending=False))\n",
    "    plt.title('Category Conversion Rates')\n",
    "    plt.xlabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x='price_diff_range', y='purchases', data=price_diff_impact)\n",
    "    plt.title('Price Difference Impact on Purchases')\n",
    "    plt.xlabel('Price Difference Range (%)')\n",
    "    plt.ylabel('Number of Purchases')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return category_popularity, category_conversion, price_diff_impact\n",
    "\n",
    "category_popularity, category_conversion, price_diff_impact = product_category_analysis()\n",
    "print(\"\\nProduct Category Analysis Results:\")\n",
    "print(\"Category popularity:\")\n",
    "print(category_popularity)\n",
    "print(\"\\nCategory conversion rates:\")\n",
    "print(category_conversion)\n",
    "print(\"\\nPrice difference impact:\")\n",
    "print(price_diff_impact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
